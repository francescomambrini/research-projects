{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse import DependencyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.dependency import DependencyCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\t~~Arabic-NYUAD\t629K~~\n",
    "2.\t~~Catalan\t472K~~\n",
    "3.\t~~Czech\t1,330K~~\n",
    "4.\t~~French\t381K~~\n",
    "5.\t~~Hindi\t316K~~\n",
    "6.\t~~Russian-SynTagRus\t988K~~\n",
    "7.\t~~Spanish-AnCora\t495K~~\n",
    "8.\t~~Latin-ITTB\t280K~~\n",
    "9.\t~~Portuguese-BR\t268K~~\n",
    "10.\t~~Norwegian-Bokmaal\t280K~~\n",
    "11.\t~~German\t277K~~\n",
    "\n",
    "Starting Network:\n",
    "lemmas only; keep punct/symbols; with deprel (labeled edges)\n",
    "\n",
    "columns:\n",
    "* lemma-head\n",
    "* lemma-dep\n",
    "* deprel\n",
    "* count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to read the log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Most of the information is now documented in the log file generated by the Python script (\"SyntacticNetwork.log\"). For each treebank, the log reports:\n",
    "1. the name of the treebank itself\n",
    "2. the number of sentences with punctuation as head that were ignored\n",
    "3. the number of sentences that were examined\n",
    "4. the Nr. of Tokens included (~200k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for point 3, the log reports that information as \"Nr. of Sentences included\". Unfortunately, that is **NOT** accurate. Considering how the counting of the sentence works, it's clear that the number reported there is the number of sentences that were processed, i.e. the sentences actually included + sentence with punctuation as head (discarded). The real \"Nr. of Sentences included\" is then calculated as:\n",
    "`Nr. reported at point 3 - Nr. reported at point 2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectively, the information n. 3 reports the number of sentences that were taken into account, some of which were discarded. That number (-1, if you're indexing them from 0) gives you also the index of the last sentence that was processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g. the log for the UD_Latin_ITTB reads:\n",
    "\n",
    "``\n",
    "INFO:root:Working with treebank: UD_Latin-ITTB\n",
    "INFO:root:Sentences with punctuation as head: 14\n",
    "INFO:root:Nr. of Sentences included: 14426\n",
    "INFO:root:Nr. of Tokens included: 200035\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14426 are the number of the sentences taken into account. The last sentence analyzed by our script is the Nr. 14426 (or the sentence indexed [14425] if you use a Python corpus reader) of the combined corpus obtained by reading both train and dev file distributed in UD.\n",
    "\n",
    "The number of sentences that were actually used to obtain our data is: 14426 - 14 (the nr. of sentences discarded, on account of their use of punctuation marks as head)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a dummy function where these accounts can be tested in the [Scrapbook](#Scrapbook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract tar for UD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgs = [\"Hindi\", \"Russian-SynTagRus\", \"Spanish-AnCora\", \"Latin-ITTB\", \"Portuguese-BR\",\"Norwegian-Bokmaal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tar = tarfile.open(\"/Users/fmambrini/Downloads/Universal Dependencies 2.0/ud-treebanks-conll2017.tgz\", \"r:gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ud-treebanks-conll2017/UD_Norwegian-Bokmaal\n",
      "ud-treebanks-conll2017/UD_Norwegian-Bokmaal/no_bokmaal-ud-dev.txt\n",
      "ud-treebanks-conll2017/UD_Norwegian-Bokmaal/stats.xml\n",
      "ud-treebanks-conll2017/UD_Norwegian-Bokmaal/no_bokmaal-ud-dev.conllu\n",
      "ud-treebanks-conll2017/UD_Norwegian-Bokmaal/no_bokmaal-ud-train.conllu\n",
      "ud-treebanks-conll2017/UD_Norwegian-Bokmaal/README.md\n",
      "ud-treebanks-conll2017/UD_Norwegian-Bokmaal/no_bokmaal-ud-train.txt\n",
      "ud-treebanks-conll2017/UD_Norwegian-Bokmaal/LICENSE.txt\n"
     ]
    }
   ],
   "source": [
    "name = lgs[-1]\n",
    "for tarinfo in tar:\n",
    "    if name in tarinfo.name:\n",
    "        print(tarinfo.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold = os.path.join(\"ud-treebanks-conll2017\", \"UD_French\")\n",
    "subdir_and_files = [tarinfo for tarinfo in tar.getmembers() if tarinfo.name.startswith(fold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subdir_and_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line of code extracts the selected directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tar.extractall(members=subdir_and_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with Hindi\n",
      "Working with Russian-SynTagRus\n",
      "Working with Spanish-AnCora\n",
      "Working with Latin-ITTB\n",
      "Working with Portuguese-BR\n",
      "Working with Norwegian-Bokmaal\n"
     ]
    }
   ],
   "source": [
    "for l in lgs:\n",
    "    print(\"Working with\", l)\n",
    "    fold = os.path.join(\"ud-treebanks-conll2017\", \"UD_\" + l)\n",
    "    subdir_and_files = [tarinfo for tarinfo in tar.getmembers() if tarinfo.name.startswith(fold)]\n",
    "    tar.extractall(members=subdir_and_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the next line could be useful to inspect the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"ud-treebanks-conll2017/UD_German/de-ud-dev.conllu\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sent_id = dev-s1\n",
      "\n",
      "# text = Manasse ist ein einzigartiger Parfümeur.\n",
      "\n",
      "1\tManasse\tManasse\tPROPN\tNN\tCase=Nom|Number=Sing\t5\tnsubj\t_\t_\n",
      "\n",
      "2\tist\tsein\tVERB\tVAFIN\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t5\tcop\t_\t_\n",
      "\n",
      "3\tein\tein\tDET\tART\tDefinite=Ind|PronType=Art\t5\tdet\t_\t_\n",
      "\n",
      "4\teinzigartiger\teinzigartig\tADJ\tADJA\tDegree=Cmp,Pos\t5\tamod\t_\t_\n",
      "\n",
      "5\tParfümeur\tParfümeur\tNOUN\tNN\t_\t0\troot\t_\tSpaceAfter=No\n",
      "\n",
      "6\t.\t.\tPUNCT\t$.\t_\t5\tpunct\t_\t_\n",
      "\n",
      "\n",
      "\n",
      "# sent_id = dev-s2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent = lines[:10]\n",
    "for s in sent: print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.32.0 (20130801.1934)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"435pt\" height=\"220pt\"\n",
       " viewBox=\"0.00 0.00 435.00 220.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 216)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"white\" points=\"-4,5 -4,-216 432,-216 432,5 -4,5\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"202\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"202\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (Parfümeur)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202,-175.597C202,-163.746 202,-147.817 202,-134.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"205.5,-134.084 202,-124.084 198.5,-134.084 205.5,-134.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"213.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"42\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (Manasse)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M161.975,-87.9434C149.938,-82.511 136.798,-76.2747 125,-70 108.801,-61.3845 91.4263,-50.9125 76.7812,-41.7045\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.3686,-38.5666 68.0502,-36.1625 74.6173,-44.4765 78.3686,-38.5666\"/>\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"130\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (ist)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;2 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>5&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M187.43,-87.5966C176.919,-75.0419 162.576,-57.9099 150.853,-43.9081\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"153.406,-41.5048 144.303,-36.084 148.039,-45.9984 153.406,-41.5048\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">cop</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\"><title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"202\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">3 (ein)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>5&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202,-87.5966C202,-75.7459 202,-59.8169 202,-46.2917\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"205.5,-46.084 202,-36.084 198.5,-46.084 205.5,-46.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"211\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"301\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (einzigartiger)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222.034,-87.5966C236.892,-74.6899 257.318,-56.9457 273.674,-42.7379\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"276.079,-45.2843 281.334,-36.084 271.489,-39.9998 276.079,-45.2843\"/>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"400\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">6 (.)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M249.262,-88.7142C264.625,-83.1219 281.662,-76.6004 297,-70 319.525,-60.3071 344.159,-48.1678 363.687,-38.1644\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"365.55,-41.1415 372.832,-33.4453 362.34,-34.9209 365.55,-41.1415\"/>\n",
       "<text text-anchor=\"middle\" x=\"348\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">punct</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<DependencyGraph with 7 nodes>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = DependencyGraph(sent, top_relation_label=\"root\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = \"ud-treebanks-conll2017/UD_French/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert CoNLLu to CoNLLx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DependencyCorpusReader doesn't work with CoNLLU: we need to convert everything to the old CoNLLX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = glob(r + \"*/*.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in fs:\n",
    "    out = f.replace(\".conllu\", \".conllx\")\n",
    "    !perl conllu_to_conllx.pl {f} > {out}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DependencyCorpusReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parsed_sents method has a small problem: it assumes \"ROOT\" as the top relation, yet at least some CoNLLU files have \"root\"; the all-caps version is what the DependencyGraph object loader expects as default, and there's no way to pass a different value to it. It is however pretty easy to overrite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def fixed_parsed_sents(self, fileids=None, top_label=\"root\"):\n",
    "    from nltk.corpus.reader.util import concat\n",
    "    from nltk.corpus.reader.dependency import DependencyCorpusView\n",
    "    from nltk.parse import DependencyGraph\n",
    "    \n",
    "    sents=concat([DependencyCorpusView(fileid, False, True, True, encoding=enc)\n",
    "                  for fileid, enc in self.abspaths(fileids, include_encoding=True)])\n",
    "    return [DependencyGraph(sent, top_relation_label=top_label, cell_separator=\"\\t\") for sent in sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(see [Section 6](#Fixing-the-problem-with-French) for the fix in line 8: `cell_separator=\"\\t\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "DependencyCorpusReader.parsed_sents = fixed_parsed_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unidep = DependencyCorpusReader(r, r\".*\\.conllx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fr-ud-dev.conllx', 'fr-ud-train.conllx']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidep.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-53103c2d82d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#parsed_dev = unidep.parsed_sents('de-ud-dev.conllx')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#parsed_train = unidep.parsed_sents('de-ud-train.conllx')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munidep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-c8b256ccf326>\u001b[0m in \u001b[0;36mfixed_parsed_sents\u001b[0;34m(self, fileids, top_label)\u001b[0m\n\u001b[1;32m      6\u001b[0m     sents=concat([DependencyCorpusView(fileid, False, True, True, encoding=enc)\n\u001b[1;32m      7\u001b[0m                   for fileid, enc in self.abspaths(fileids, include_encoding=True)])\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDependencyGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_relation_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-c8b256ccf326>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m     sents=concat([DependencyCorpusView(fileid, False, True, True, encoding=enc)\n\u001b[1;32m      7\u001b[0m                   for fileid, enc in self.abspaths(fileids, include_encoding=True)])\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDependencyGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_relation_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/fmambrini/anaconda/lib/python3.4/site-packages/nltk/parse/dependencygraph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tree_str, cell_extractor, zero_based, cell_separator, top_relation_label)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mzero_based\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_based\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mcell_separator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcell_separator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mtop_relation_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_relation_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             )\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fmambrini/anaconda/lib/python3.4/site-packages/nltk/parse/dependencygraph.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self, input_, cell_extractor, zero_based, cell_separator, top_relation_label)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0mcell_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mcell_number\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcell_extractor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#parsed_dev = unidep.parsed_sents('de-ud-dev.conllx')\n",
    "#parsed_train = unidep.parsed_sents('de-ud-train.conllx')\n",
    "parsed = unidep.parsed_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = parsed[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the triples method yields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('meditabitur', 'VERB'), 'obj', ('veritatem', 'NOUN'))\n",
      "(('meditabitur', 'VERB'), 'nsubj:pass', ('guttur', 'NOUN'))\n",
      "(('guttur', 'NOUN'), 'det', ('meum', 'DET'))\n",
      "(('meditabitur', 'VERB'), 'conj', ('detestabuntur', 'VERB'))\n",
      "(('detestabuntur', 'VERB'), 'punct', (',', 'PUNCT'))\n",
      "(('detestabuntur', 'VERB'), 'cc', ('et', 'CCONJ'))\n",
      "(('detestabuntur', 'VERB'), 'nsubj:pass', ('labia', 'NOUN'))\n",
      "(('labia', 'NOUN'), 'det', ('mea', 'DET'))\n",
      "(('detestabuntur', 'VERB'), 'obj', ('impium', 'ADJ'))\n",
      "(('meditabitur', 'VERB'), 'punct', ('.', 'PUNCT'))\n"
     ]
    }
   ],
   "source": [
    "for n in d.triples(): print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to be able what kind of column to output there, e.g. whether I want the word or the lemma, or whether the ctag or the full tag. For that we have to ovverrite the method as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def new_triples(self, node=None, word_label = \"word\", tag_label=\"ctag\"):\n",
    "        \"\"\"\n",
    "        Extract dependency triples of the form:\n",
    "        ((head word, head tag), rel, (dep word, dep tag))\n",
    "        \"\"\"\n",
    "        \n",
    "        from itertools import chain\n",
    "        \n",
    "        assert word_label in [\"word\", \"lemma\"], \"Select either word or lemma as label!\"\n",
    "        assert tag_label in [\"tag\", \"ctag\"], \"Select either tag or ctag as label!\"\n",
    "\n",
    "        if not node:\n",
    "            node = self.root\n",
    "\n",
    "        head = (node[word_label], node[tag_label])\n",
    "        for i in sorted(chain.from_iterable(node['deps'].values())):\n",
    "            dep = self.get_by_address(i)\n",
    "            yield (head, dep['rel'], (dep[word_label], dep[tag_label]))\n",
    "            for triple in self.triples(node=dep, word_label=word_label, tag_label=tag_label):\n",
    "                yield triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "DependencyGraph.triples = new_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address': 2,\n",
       " 'ctag': 'VERB',\n",
       " 'deps': defaultdict(list,\n",
       "             {'conj': [9], 'nsubj:pass': [3], 'obj': [1], 'punct': [11]}),\n",
       " 'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Fut|VerbForm=Fin|Voice=Pass',\n",
       " 'head': 0,\n",
       " 'lemma': 'meditor',\n",
       " 'rel': 'root',\n",
       " 'tag': 'J3|modJ|tem3|gen6|stAC',\n",
       " 'word': 'meditabitur'}"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.nodes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('meditabitur', 'VERB'), 'obj', ('veritatem', 'NOUN'))\n",
      "(('meditabitur', 'VERB'), 'nsubj:pass', ('guttur', 'NOUN'))\n",
      "(('guttur', 'NOUN'), 'det', ('meum', 'DET'))\n",
      "(('meditabitur', 'VERB'), 'conj', ('detestabuntur', 'VERB'))\n",
      "(('detestabuntur', 'VERB'), 'punct', (',', 'PUNCT'))\n",
      "(('detestabuntur', 'VERB'), 'cc', ('et', 'CCONJ'))\n",
      "(('detestabuntur', 'VERB'), 'nsubj:pass', ('labia', 'NOUN'))\n",
      "(('labia', 'NOUN'), 'det', ('mea', 'DET'))\n",
      "(('detestabuntur', 'VERB'), 'obj', ('impium', 'ADJ'))\n",
      "(('meditabitur', 'VERB'), 'punct', ('.', 'PUNCT'))\n"
     ]
    }
   ],
   "source": [
    "for n in d.triples(): print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('meditor', 'VERB'), 'obj', ('veritas', 'NOUN'))\n",
      "(('meditor', 'VERB'), 'nsubj:pass', ('guttur', 'NOUN'))\n",
      "(('guttur', 'NOUN'), 'det', ('meus', 'DET'))\n",
      "(('meditor', 'VERB'), 'conj', ('detestor', 'VERB'))\n",
      "(('detestor', 'VERB'), 'punct', (',', 'PUNCT'))\n",
      "(('detestor', 'VERB'), 'cc', ('et', 'CCONJ'))\n",
      "(('detestor', 'VERB'), 'nsubj:pass', ('labium', 'NOUN'))\n",
      "(('labium', 'NOUN'), 'det', ('meus', 'DET'))\n",
      "(('detestor', 'VERB'), 'obj', ('impius', 'ADJ'))\n",
      "(('meditor', 'VERB'), 'punct', ('.', 'PUNCT'))\n"
     ]
    }
   ],
   "source": [
    "for n in d.triples(word_label=\"lemma\", tag_label=\"ctag\"): print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the network data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extract a series of: Lemma-head -[rel]-> Lemma-dep\n",
    "\n",
    "Ultimately we need a tab like e.g.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Head-Lemma    | Dep-Lemma     | Relation | Count |\n",
    "| ------------- |:------------- |:-----:   |------:|\n",
    "| haben         | Gelegenheit   |    obj   | 100   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we start collecting a dataframe: head-lemma, dep-lemma, relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided that:\n",
    "* feat of dep-rel (e.g. nsubj:pass) are simplified: nsubj:pass >> nsubj\n",
    "* punctuation is left out (we record on a log the number of cases and the index of sentences where tokens tagged as PUNCT are heads of a relation)\n",
    "* but before, we cleaned the data: we skipped those sentences where punctuation marks are used as head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def hasPunctHead(parsed_sent):\n",
    "    for n in parsed_sent.triples():\n",
    "        if n[0][1] == \"PUNCT\":\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def countNodes(parsed_sent):\n",
    "    \"\"\"count the tokens in a sentence (purging punctuation);\n",
    "    :return: int: the count\n",
    "    \"\"\"\n",
    "    i =0\n",
    "    for k,v in parsed_sent.nodes.items():\n",
    "        if v[\"ctag\"] == \"PUNCT\" or v[\"ctag\"] == \"TOP\":\n",
    "            continue\n",
    "        else:\n",
    "            i +=1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def getNetworkDataFrames(parsed_sents, threshold=200000):\n",
    "    \"\"\"Process the parsed DependencyGraphs and return the DFs with \n",
    "    :param: parsed_sents: list of parsed Dependency Graphs\n",
    "    :param: threshold: the iteration over sentences will stop after the sentence that \n",
    "    exceeds the give threshold\n",
    "    :return: tuple of DataFrames (head-dep values, cooccurence values)\n",
    "    \"\"\"\n",
    "    head, dep, rel = [], [], []\n",
    "    w1, w2 = [], []\n",
    "    token_count = 0\n",
    "    puncthead = 0\n",
    "    for i,s in enumerate(parsed_sents, start=1):\n",
    "        if hasPunctHead(s) == False:\n",
    "            #co-occurence data\n",
    "            sent = getCoocInSent(s)\n",
    "            for line in sent:\n",
    "                w1.append(line[0])\n",
    "                w2.append(line[1])\n",
    "            #syntax-based\n",
    "            for n in s.triples(word_label=\"lemma\"):\n",
    "                if n[0][1] == 'PUNCT':\n",
    "                    print(\"{}: Punctuation as head!\".format(i-1))\n",
    "                    break\n",
    "                if n[2][1] == \"PUNCT\":\n",
    "                    continue\n",
    "                head.append(n[0][0])\n",
    "                #htag.append(n[0][1])\n",
    "                #clean relation feature:\n",
    "                rel.append(n[1].split(\":\")[0])\n",
    "                dep.append(n[2][0])\n",
    "                #dtag.append(n[2][1])\n",
    "            token_count = token_count + countNodes(s)\n",
    "        else:\n",
    "            puncthead += 1\n",
    "        if token_count > threshold:\n",
    "            logging.info(\"Sentences with punctuation as head: {}\".format(puncthead))\n",
    "            logging.info(\"Nr. of Sentences included: {}\".format(i))\n",
    "            logging.info(\"Nr. of Tokens included: {}\".format(token_count))\n",
    "            print(\"Finalizing the Dataframe at {} tokens after {} sentences\".format(token_count, i))\n",
    "            break\n",
    "    df_dep = pd.DataFrame({\"Head_Lemma\" : head, \"Dep_Lemma\" : dep, \"Relation\" : rel })\n",
    "    df_dep = df_dep[[\"Head_Lemma\", \"Dep_Lemma\", \"Relation\"]]\n",
    "    df_co = pd.DataFrame({\"Prec\": w1, \"Seq\" : w2})\n",
    "    return (df_dep, df_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing the Dataframe at 200006 tokens after 14184 sentences\n"
     ]
    }
   ],
   "source": [
    "df_dep_lemma = getHeadDepDataFrame(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280734"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unidep.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dep_Lemma</th>\n",
       "      <th>Head_Lemma</th>\n",
       "      <th>Relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185820</th>\n",
       "      <td>  negativní</td>\n",
       "      <td>     účinek</td>\n",
       "      <td>   amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185821</th>\n",
       "      <td>    doprava</td>\n",
       "      <td>     účinek</td>\n",
       "      <td>   nmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185822</th>\n",
       "      <td>   silniční</td>\n",
       "      <td>    doprava</td>\n",
       "      <td>   amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185823</th>\n",
       "      <td>  prostředí</td>\n",
       "      <td>     účinek</td>\n",
       "      <td>   nmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185824</th>\n",
       "      <td>         na</td>\n",
       "      <td>  prostředí</td>\n",
       "      <td>   case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185825</th>\n",
       "      <td>    životní</td>\n",
       "      <td>  prostředí</td>\n",
       "      <td>   amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185826</th>\n",
       "      <td>       země</td>\n",
       "      <td> potřebovat</td>\n",
       "      <td>  xcomp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185827</th>\n",
       "      <td>       jako</td>\n",
       "      <td>       země</td>\n",
       "      <td>   mark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185828</th>\n",
       "      <td>  tranzitní</td>\n",
       "      <td>       země</td>\n",
       "      <td>   amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185829</th>\n",
       "      <td>   převážně</td>\n",
       "      <td>  tranzitní</td>\n",
       "      <td> advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185830</th>\n",
       "      <td>    zlepšit</td>\n",
       "      <td> potřebovat</td>\n",
       "      <td>  xcomp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185831</th>\n",
       "      <td> koordinace</td>\n",
       "      <td>    zlepšit</td>\n",
       "      <td>    obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185832</th>\n",
       "      <td>     systém</td>\n",
       "      <td> koordinace</td>\n",
       "      <td>   nmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185833</th>\n",
       "      <td>   přeprava</td>\n",
       "      <td>     systém</td>\n",
       "      <td>   nmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185834</th>\n",
       "      <td>      firma</td>\n",
       "      <td>       moci</td>\n",
       "      <td>  nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185835</th>\n",
       "      <td>     takový</td>\n",
       "      <td>      firma</td>\n",
       "      <td>    det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185836</th>\n",
       "      <td>        můj</td>\n",
       "      <td>      firma</td>\n",
       "      <td>  advcl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185837</th>\n",
       "      <td>       jako</td>\n",
       "      <td>        můj</td>\n",
       "      <td>   mark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185838</th>\n",
       "      <td>   napomoci</td>\n",
       "      <td>       moci</td>\n",
       "      <td>  xcomp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185839</th>\n",
       "      <td>        ten</td>\n",
       "      <td>   napomoci</td>\n",
       "      <td>    obj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dep_Lemma  Head_Lemma Relation\n",
       "185820   negativní      účinek     amod\n",
       "185821     doprava      účinek     nmod\n",
       "185822    silniční     doprava     amod\n",
       "185823   prostředí      účinek     nmod\n",
       "185824          na   prostředí     case\n",
       "185825     životní   prostředí     amod\n",
       "185826        země  potřebovat    xcomp\n",
       "185827        jako        země     mark\n",
       "185828   tranzitní        země     amod\n",
       "185829    převážně   tranzitní   advmod\n",
       "185830     zlepšit  potřebovat    xcomp\n",
       "185831  koordinace     zlepšit      obj\n",
       "185832      systém  koordinace     nmod\n",
       "185833    přeprava      systém     nmod\n",
       "185834       firma        moci    nsubj\n",
       "185835      takový       firma      det\n",
       "185836         můj       firma    advcl\n",
       "185837        jako         můj     mark\n",
       "185838    napomoci        moci    xcomp\n",
       "185839         ten    napomoci      obj"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dep_lemma.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_nodeprel = df_dep_lemma[[\"Dep_Lemma\",\"Head_Lemma\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dep_Lemma</th>\n",
       "      <th>Head_Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> telefon</td>\n",
       "      <td>       rada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>      na</td>\n",
       "      <td>    telefon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> poradit</td>\n",
       "      <td> potřebovat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>  rychle</td>\n",
       "      <td>    poradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> telefon</td>\n",
       "      <td>   zvednout</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dep_Lemma  Head_Lemma\n",
       "0   telefon        rada\n",
       "1        na     telefon\n",
       "2   poradit  potřebovat\n",
       "3    rychle     poradit\n",
       "4   telefon    zvednout"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodeprel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab = pd.pivot_table(df_dep_lemma,index=[\"Dep_Lemma\",\"Head_Lemma\", \"Relation\"], aggfunc=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab_nodep = pd.pivot_table(df_nodeprel, index=[\"Dep_Lemma\",\"Head_Lemma\"], aggfunc=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dep_Lemma  Head_Lemma  Relation\n",
       "%          %           conj        1\n",
       "                       orphan      1\n",
       "           0.2         nmod        1\n",
       "           0.5         nmod        1\n",
       "           0.6         nmod        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdf = tab.to_frame(\"Count\")\n",
    "newdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dep_Lemma</th>\n",
       "      <th>Head_Lemma</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> %</td>\n",
       "      <td>   %</td>\n",
       "      <td>   conj</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> %</td>\n",
       "      <td>   %</td>\n",
       "      <td> orphan</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> %</td>\n",
       "      <td> 0.2</td>\n",
       "      <td>   nmod</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> %</td>\n",
       "      <td> 0.5</td>\n",
       "      <td>   nmod</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> %</td>\n",
       "      <td> 0.6</td>\n",
       "      <td>   nmod</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dep_Lemma Head_Lemma Relation  Count\n",
       "0         %          %     conj      1\n",
       "1         %          %   orphan      1\n",
       "2         %        0.2     nmod      1\n",
       "3         %        0.5     nmod      1\n",
       "4         %        0.6     nmod      1"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newdf = newdf[[\"Head_Lemma\", \"Dep_Lemma\", \"Relation\", \"Count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Head_Lemma</th>\n",
       "      <th>Dep_Lemma</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>   %</td>\n",
       "      <td> %</td>\n",
       "      <td>   conj</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>   %</td>\n",
       "      <td> %</td>\n",
       "      <td> orphan</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0.2</td>\n",
       "      <td> %</td>\n",
       "      <td>   nmod</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0.5</td>\n",
       "      <td> %</td>\n",
       "      <td>   nmod</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0.6</td>\n",
       "      <td> %</td>\n",
       "      <td>   nmod</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Head_Lemma Dep_Lemma Relation  Count\n",
       "0          %         %     conj      1\n",
       "1          %         %   orphan      1\n",
       "2        0.2         %     nmod      1\n",
       "3        0.5         %     nmod      1\n",
       "4        0.6         %     nmod      1"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dep_Lemma    Head_Lemma  Relation\n",
       "2-NO-A3---   sum         ccomp       1\n",
       "4-O--------  causa       mark        1\n",
       "             deficio     mark        1\n",
       "             dependeo    mark        1\n",
       "             semper      mark        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab_nodep.to_csv(\"cz_syntax_no-deprel.csv\", sep=\"\\t\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooccurrence Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCoocInSent(parsed_sent):\n",
    "    ns = parsed_sent.nodes\n",
    "    lemma_list = [ns[w][\"lemma\"] for w in ns.keys() \n",
    "              if ns[w][\"lemma\"] != None and ns[w][\"ctag\"] != \"PUNCT\"]\n",
    "    return list(bigrams(lemma_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def coocData(parsed_sents):\n",
    "    w1, w2 = [], []\n",
    "    for s in parsed_sents:\n",
    "        sent = getCoocInSent(s)\n",
    "        for line in sent:\n",
    "            w1.append(line[0])\n",
    "            w2.append(line[1])\n",
    "    return pd.DataFrame({\"Prec\": w1, \"Seq\" : w2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('multitudo', 'usus'),\n",
       " ('usus', 'qui'),\n",
       " ('qui', 'in'),\n",
       " ('in', 'res'),\n",
       " ('res', 'nomino'),\n",
       " ('nomino', 'sequor'),\n",
       " ('sequor', 'philosophus'),\n",
       " ('philosophus', 'censeo'),\n",
       " ('censeo', 'communis'),\n",
       " ('communis', 'obtineo'),\n",
       " ('obtineo', 'ut'),\n",
       " ('ut', 'sapiens'),\n",
       " ('sapiens', 'dico'),\n",
       " ('dico', 'qui'),\n",
       " ('qui', 'res'),\n",
       " ('res', 'directus'),\n",
       " ('directus', 'ordino'),\n",
       " ('ordino', 'et'),\n",
       " ('et', 'is'),\n",
       " ('is', 'bene'),\n",
       " ('bene', 'guberno')]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCoocInSent(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = parsed[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multitudinis\tC1|grn1|casB|gen2|stRS\t2\n",
      "usus\tD1|grn1|casA|gen1|stAN\t13\n",
      ",\tPunc\t10\n",
      "quem\tF1|grn1|casD|gen1|stPV\t10\n",
      "in\tS4|stRL\t6\n",
      "rebus\tE1|grn1|casO|gen2|stRS\t8\n",
      "nominandis\tJ2|modO|grp1|casO|gen2|stAE\t6\n",
      "sequendum\tL2|modO|grp1|casD|gen1|stAV\t10\n",
      "philosophus\tB1|grn1|casA|gen1|stRS\t10\n",
      "censet\tK3|modA|tem1|gen6|stAC\t2\n",
      ",\tPunc\t10\n",
      "communiter\tC1|grn1|casG|stAN\t13\n",
      "obtinuit\tK3|modA|tem4|gen6|stAV\t0\n",
      "ut\tO4|vgr1|stRL\t15\n",
      "sapientes\tC1|grn1|casJ|gen1|stAC\t13\n",
      "dicantur\tL3|modK|tem1|gen9|stAE\t15\n",
      "qui\tF1|grn1|casJ|gen1|stPV\t20\n",
      "res\tE1|grn1|casM|gen2|stRS\t20\n",
      "directe\tB1|grn1|casG|stAV\t20\n",
      "ordinant\tJ3|modA|tem1|gen9|stAV\t15\n",
      "et\tO4|stRL\t24\n",
      "eas\tF1|grn1|casM|gen2|stPV\t24\n",
      "bene\tO4|stRL\t24\n",
      "gubernant\tJ3|modA|tem1|gen9|stAV\t20\n",
      ".\tPunc\t13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(d.to_conll(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ns = d.nodes\n",
    "lemma_list = [ns[w][\"lemma\"] for w in ns.keys() \n",
    "              if ns[w][\"lemma\"] != None and ns[w][\"ctag\"] != \"PUNCT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multitudo',\n",
       " 'usus',\n",
       " 'qui',\n",
       " 'in',\n",
       " 'res',\n",
       " 'nomino',\n",
       " 'sequor',\n",
       " 'philosophus',\n",
       " 'censeo',\n",
       " 'communis',\n",
       " 'obtineo',\n",
       " 'ut',\n",
       " 'sapiens',\n",
       " 'dico',\n",
       " 'qui',\n",
       " 'res',\n",
       " 'directus',\n",
       " 'ordino',\n",
       " 'et',\n",
       " 'is',\n",
       " 'bene',\n",
       " 'guberno']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('multitudo', 'usus'),\n",
       " ('usus', 'qui'),\n",
       " ('qui', 'in'),\n",
       " ('in', 'res'),\n",
       " ('res', 'nomino'),\n",
       " ('nomino', 'sequor'),\n",
       " ('sequor', 'philosophus'),\n",
       " ('philosophus', 'censeo'),\n",
       " ('censeo', 'communis'),\n",
       " ('communis', 'obtineo'),\n",
       " ('obtineo', 'ut'),\n",
       " ('ut', 'sapiens'),\n",
       " ('sapiens', 'dico'),\n",
       " ('dico', 'qui'),\n",
       " ('qui', 'res'),\n",
       " ('res', 'directus'),\n",
       " ('directus', 'ordino'),\n",
       " ('ordino', 'et'),\n",
       " ('et', 'is'),\n",
       " ('is', 'bene'),\n",
       " ('bene', 'guberno')]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams(lemma_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cooc = coocData(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prec</th>\n",
       "      <th>Seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>      qui</td>\n",
       "      <td>      sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>      sum</td>\n",
       "      <td> officium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> officium</td>\n",
       "      <td>  sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>  veritas</td>\n",
       "      <td>  meditor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>  meditor</td>\n",
       "      <td>   guttur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prec       Seq\n",
       "0       qui       sum\n",
       "1       sum  officium\n",
       "2  officium   sapiens\n",
       "3   veritas   meditor\n",
       "4   meditor    guttur"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cooc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = unidep.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the problem with French"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parsing of the French data with the DependencyGraph class raises an Assertion Error. We'll try to diagnose it and fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.util import concat\n",
    "from nltk.corpus.reader.dependency import DependencyCorpusView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents=concat([DependencyCorpusView(fileid, False, True, True, encoding=enc)\n",
    "                  for fileid, enc in unidep.abspaths(unidep.fileids(), include_encoding=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assertion error at sentence 16 (1\tComprenant\tcompren)\n",
      "Assertion error at sentence 91 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 108 (1\tEntremont\tEntremon)\n",
      "Assertion error at sentence 195 (1\tCelui-ci\tcelui-ci\t)\n",
      "Assertion error at sentence 209 (1\tLes\tle\tDET\tDET\tDef)\n",
      "Assertion error at sentence 369 (1\tSelon\tselon\tADP\tAD)\n",
      "Assertion error at sentence 395 (1\tLa\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 590 (1\tEn\ten\tADP\tADP\t_\t2\t)\n",
      "Assertion error at sentence 808 (1\tLes\tle\tDET\tDET\tDef)\n",
      "Assertion error at sentence 864 (1\tSa\tson\tDET\tDET\tGen)\n",
      "Assertion error at sentence 902 (1\tde\tde\tADP\tADP\t_\t3\t)\n",
      "Assertion error at sentence 1147 (1\tEnviron\tenviron\tAD)\n",
      "Assertion error at sentence 1550 (1\tÀ\tà\tADP\tADP\t_\t6\tca)\n",
      "Assertion error at sentence 1618 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 1636 (1\tLa\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 1707 (1\tElle\telle\tPRON\tPRO)\n",
      "Assertion error at sentence 1717 (1\tGraham\tGraham\tPROP)\n",
      "Assertion error at sentence 1737 (1\tAvec\tavec\tADP\tADP\t)\n",
      "Assertion error at sentence 1787 (1\tCulminant\tculminer)\n",
      "Assertion error at sentence 1896 (1\tL'\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 2030 (1\tIl\til\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 2302 (1\tCependant\tcependan)\n",
      "Assertion error at sentence 2669 (1\tÀ\tà\tADP\tADP\t_\t4\tca)\n",
      "Assertion error at sentence 2834 (1\tIl\til\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 3241 (1\tLes\tle\tDET\tDET\tDef)\n",
      "Assertion error at sentence 3431 (1\tSelon\tselon\tADP\tAD)\n",
      "Assertion error at sentence 3547 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 3609 (1\tTout\ttout\tDET\tDET\t)\n",
      "Assertion error at sentence 3618 (1\tFinalement\tfinalem)\n",
      "Assertion error at sentence 3620 (1\tL'\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 3711 (1\tMuro\tMuro\tPROPN\tPR)\n",
      "Assertion error at sentence 3867 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 4387 (1\tElle\telle\tPRON\tPRO)\n",
      "Assertion error at sentence 4417 (1\tDepuis\tdepuis\tADP\t)\n",
      "Assertion error at sentence 4439 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 4592 (1\tPourtant\tpourtant\t)\n",
      "Assertion error at sentence 4888 (1\t«\t«\tPUNCT\tPUNCT\t_\t)\n",
      "Assertion error at sentence 5016 (1\tEn\ten\tADP\tADP\t_\t2\t)\n",
      "Assertion error at sentence 5360 (1\tLes\tle\tDET\tDET\tDef)\n",
      "Assertion error at sentence 5377 (1\tC'\tce\tPRON\tPRON\tNu)\n",
      "Assertion error at sentence 5658 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 5693 (1\tD'\tde\tADP\tADP\t_\t3\t)\n",
      "Assertion error at sentence 5711 (1\tIl\til\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 5736 (1\tLes\tle\tDET\tDET\tDef)\n",
      "Assertion error at sentence 5776 (1\tEn\ten\tADP\tADP\t_\t2\t)\n",
      "Assertion error at sentence 5897 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 5922 (1\tLa\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 6132 (1\tL'\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 6143 (1\tSa\tson\tDET\tDET\tGen)\n",
      "Assertion error at sentence 6188 (1\tDans\tdans\tADP\tADP\t)\n",
      "Assertion error at sentence 6362 (1\tIls\til\tPRON\tPRON\tG)\n",
      "Assertion error at sentence 6430 (1\tSon\tson\tDET\tDET\tGe)\n",
      "Assertion error at sentence 6811 (1\tElles\til\tPRON\tPRON)\n",
      "Assertion error at sentence 6866 (1\tLa\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 6956 (1\tElle\telle\tPRON\tPRO)\n",
      "Assertion error at sentence 7007 (1\tDurant\tdurant\tADP\t)\n",
      "Assertion error at sentence 7037 (1\tIl\til\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 7093 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 7313 (1\tSelon\tselon\tADP\tAD)\n",
      "Assertion error at sentence 7316 (1\tLa\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 7550 (1\tIl\til\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 7586 (1\tEnsuite\tensuite\tAD)\n",
      "Assertion error at sentence 7714 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 7783 (1\tà\tà\tADP\tADP\t_\t3\tca)\n",
      "Assertion error at sentence 7880 (1\tAinsi\tainsi\tADV\tAD)\n",
      "Assertion error at sentence 7998 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 8003 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 8032 (1\tCe\tce\tDET\tDET\tGend)\n",
      "Assertion error at sentence 8278 (1\tOn\ton\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 8344 (1\tConseiller\tconseil)\n",
      "Assertion error at sentence 8485 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 8522 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 8781 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 8822 (1\tCinq\tCinq\tNUM\tNUM\t)\n",
      "Assertion error at sentence 8852 (1\tL'\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 9012 (1\tOn\ton\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 9144 (1\tCelles-ci\tcelui-ci)\n",
      "Assertion error at sentence 9269 (1\tPrès\tprès\tADP\tADP\t)\n",
      "Assertion error at sentence 9347 (1\tDes\tun\tDET\tDET\tDef)\n",
      "Assertion error at sentence 9623 (1\tEn\ten\tADP\tADP\t_\t2\t)\n",
      "Assertion error at sentence 9683 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 9780 (1\tDès\tdès\tADP\tADP\t_\t)\n",
      "Assertion error at sentence 9847 (1\tSitué\tsituer\tVERB\t)\n",
      "Assertion error at sentence 10075 (1\tEn\ten\tADP\tADP\t_\t2\t)\n",
      "Assertion error at sentence 10351 (1\tL'\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 10437 (1\tSa\tson\tDET\tDET\tGen)\n",
      "Assertion error at sentence 10448 (1\tLa\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 11032 (1\tEn\ten\tADP\tADP\t_\t2\t)\n",
      "Assertion error at sentence 11064 (1\tAvec\tavec\tADP\tADP\t)\n",
      "Assertion error at sentence 11279 (1\tIl\til\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 11307 (1\tElle\telle\tPRON\tPRO)\n",
      "Assertion error at sentence 11572 (1\tLa\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 11649 (1\tEn\ten\tADP\tADP\t_\t2\t)\n",
      "Assertion error at sentence 11667 (1\tIl\til\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 11690 (1\tOn\ton\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 11777 (1\tUn\tun\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 11971 (1\tSa\tson\tDET\tDET\tGen)\n",
      "Assertion error at sentence 12312 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 12676 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 12694 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 12931 (1\tOn\ton\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 13042 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 13374 (1\tAprès\taprès\tADP\tAD)\n",
      "Assertion error at sentence 13827 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 13859 (1\tIl\til\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 13863 (1\tà\tà\tADP\tADP\t_\t3\tca)\n",
      "Assertion error at sentence 13936 (1\tUn\tun\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 14010 (1\tLes\tle\tDET\tDET\tDef)\n",
      "Assertion error at sentence 14074 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 14182 (1\tDepuis\tdepuis\tADP\t)\n",
      "Assertion error at sentence 14232 (1\tEnviron\tenviron\tAD)\n",
      "Assertion error at sentence 14311 (1\tPour\tpour\tADP\tADP\t)\n",
      "Assertion error at sentence 14478 (1\tLa\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 14486 (1\tLa\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 14544 (1\tLa\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 14614 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 14783 (1\tAutre\tautre\tADJ\tAD)\n",
      "Assertion error at sentence 15281 (1\tPour\tpour\tADP\tADP\t)\n",
      "Assertion error at sentence 15339 (1\tTolosa\tTolosa\tPROP)\n",
      "Assertion error at sentence 15442 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 15564 (1\tLe\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 15686 (1\tEn\ten\tADP\tADP\t_\t2\t)\n",
      "Assertion error at sentence 15756 (1\tEn\ten\tADP\tADP\t_\t2\t)\n",
      "Assertion error at sentence 15778 (1\tL'\tle\tDET\tDET\tDefi)\n",
      "Assertion error at sentence 15810 (1\tIl\til\tPRON\tPRON\tGe)\n",
      "Assertion error at sentence 16003 (1\tCela\tcela\tPRON\tPRO)\n"
     ]
    }
   ],
   "source": [
    "wrong_sent = []\n",
    "for i,s in enumerate(sents):\n",
    "    try:\n",
    "        d = DependencyGraph(s, top_relation_label=\"root\")\n",
    "    except AssertionError:\n",
    "        wrong_sent.append((i, s))\n",
    "        print(\"Assertion error at sentence {} ({})\".format(i, s[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tComprenant\tcomprendre\tVERB\tVERB\tTense=Pres|VerbForm=Part\t17\tacl\t_\t_\n",
      "2\tsix\tsix\tNUM\tNUM\t_\t3\tnummod\t_\t_\n",
      "3\tsommets\tsommet\tNOUN\tNOUN\tGender=Masc|Number=Plur\t1\tobj\t_\t_\n",
      "4\tdont\tdont\tPRON\tPRON\tPronType=Rel\t6\tnmod\t_\t_\n",
      "5\tun\tun\tDET\tDET\tDefinite=Ind|Gender=Masc|Number=Sing|PronType=Art\t6\tdet\t_\t_\n",
      "6\tpoint\tpoint\tNOUN\tNOUN\tGender=Masc|Number=Sing\t3\tappos\t_\t_\n",
      "7\tculminant\tculminer\tVERB\tVERB\tTense=Pres|VerbForm=Part\t6\tacl\t_\t_\n",
      "8\tà\tà\tADP\tADP\t_\t10\tcase\t_\t_\n",
      "9\t2 001\t2 001\tNUM\tNUM\t_\t10\tnummod\t_\t_\n",
      "10\tmètres\tmètre\tNOUN\tNOUN\tGender=Masc|Number=Plur\t7\tobl\t_\t_\n",
      "11\tet\tet\tCCONJ\tCCONJ\t_\t13\tcc\t_\t_\n",
      "12\tune\tun\tDET\tDET\tDefinite=Ind|Gender=Fem|Number=Sing|PronType=Art\t13\tdet\t_\t_\n",
      "13\tarrivée\tarrivée\tNOUN\tNOUN\tGender=Fem|Number=Sing\t6\tconj\t_\t_\n",
      "14\ten\ten\tADP\tADP\t_\t15\tcase\t_\t_\n",
      "15\taltitude\taltitude\tNOUN\tNOUN\tGender=Fem|Number=Sing\t13\tnmod\t_\t_\n",
      "16\t,\t,\tPUNCT\tPUNCT\t_\t1\tpunct\t_\t_\n",
      "17\tc'\tce\tPRON\tPRON\tNumber=Sing|Person=3|PronType=Dem\t20\tnsubj\t_\t_\n",
      "18\test\têtre\tAUX\tAUX\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t20\tcop\t_\t_\n",
      "19\tune\tun\tDET\tDET\tDefinite=Ind|Gender=Fem|Number=Sing|PronType=Art\t20\tdet\t_\t_\n",
      "20\tétape\tétape\tNOUN\tNOUN\tGender=Fem|Number=Sing\t0\troot\t_\t_\n",
      "21\ttypique\ttypique\tADJ\tADJ\tGender=Fem|Number=Sing\t20\tamod\t_\t_\n",
      "22\tde\tde\tADP\tADP\t_\t23\tcase\t_\t_\n",
      "23\tmontagne\tmontagne\tNOUN\tNOUN\tGender=Fem|Number=Sing\t21\tobl\t_\t_\n",
      "24\t.\t.\tPUNCT\tPUNCT\t_\t20\tpunct\t_\t_\n"
     ]
    }
   ],
   "source": [
    "print(wrong_sent[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = wrong_sent[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.32.0 (20130801.1934)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"464pt\" height=\"396pt\"\n",
       " viewBox=\"0.00 0.00 464.00 396.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 392)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"white\" points=\"-4,5 -4,-392 461,-392 461,5 -4,5\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"284\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node2\" class=\"node\"><title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"284\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">6 (groupe)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M284,-351.597C284,-339.746 284,-323.817 284,-310.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"287.5,-310.084 284,-300.084 280.5,-310.084 287.5,-310.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"295.5\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"102\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (canton)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;2 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>6&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M247.607,-263.803C218.746,-250.166 178.256,-231.033 147.298,-216.404\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"148.556,-213.128 138.019,-212.02 145.565,-219.457 148.556,-213.128\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node8\" class=\"node\"><title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"231\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">10 (compte)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;10 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>6&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M273.275,-263.597C265.682,-251.277 255.373,-234.549 246.836,-220.696\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"249.755,-218.761 241.529,-212.084 243.795,-222.433 249.755,-218.761\"/>\n",
       "<text text-anchor=\"middle\" x=\"275.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"338\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">8 (commune)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M294.928,-263.597C302.664,-251.277 313.167,-234.549 321.865,-220.696\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"324.919,-222.414 327.273,-212.084 318.991,-218.692 324.919,-222.414\"/>\n",
       "<text text-anchor=\"middle\" x=\"325\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">obj</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node10\" class=\"node\"><title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"429\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">13 (.)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;13 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>6&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.994,-263.803C335.96,-250.183 368.167,-231.08 392.82,-216.459\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"394.714,-219.405 401.529,-211.293 391.143,-213.384 394.714,-219.405\"/>\n",
       "<text text-anchor=\"middle\" x=\"386\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">punct</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (Le)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.8226,-175.597C75.8737,-163.042 60.9331,-145.91 48.7222,-131.908\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51.1093,-129.32 41.8988,-124.084 45.8337,-133.921 51.1093,-129.32\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node5\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"102\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (Ulis)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102,-175.597C102,-163.746 102,-147.817 102,-134.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"105.5,-134.084 102,-124.084 98.5001,-134.084 105.5,-134.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"118\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node6\" class=\"node\"><title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"66\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">3 (de)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>5&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M94.7149,-87.5966C89.6558,-75.5112 82.8214,-59.1844 77.0893,-45.4911\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"80.2414,-43.9569 73.1514,-36.084 73.7843,-46.6599 80.2414,-43.9569\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.5\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node7\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"138\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (les)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.285,-87.5966C114.344,-75.5112 121.179,-59.1844 126.911,-45.4911\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.216,-46.6599 130.849,-36.084 123.759,-43.9569 130.216,-46.6599\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node12\" class=\"node\"><title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">9 (et)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;9 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>10&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220.072,-175.597C212.336,-163.277 201.833,-146.549 193.135,-132.696\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.009,-130.692 187.727,-124.084 190.081,-134.414 196.009,-130.692\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">cc</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">12 (habitants)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M238.69,-175.597C244.03,-163.511 251.244,-147.184 257.295,-133.491\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"260.611,-134.645 261.451,-124.084 254.208,-131.816 260.611,-134.645\"/>\n",
       "<text text-anchor=\"middle\" x=\"263\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">obj</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node11\" class=\"node\"><title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"363\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">7 (une)</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;7 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>8&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M343.059,-175.597C346.538,-163.629 351.226,-147.501 355.183,-133.891\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"358.603,-134.664 358.034,-124.084 351.881,-132.709 358.603,-134.664\"/>\n",
       "<text text-anchor=\"middle\" x=\"362\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node14\" class=\"node\"><title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">11 (25 785)</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;11 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>12&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M269,-87.5966C269,-75.7459 269,-59.8169 269,-46.2917\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"272.5,-46.084 269,-36.084 265.5,-46.084 272.5,-46.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"294\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">nummod</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<DependencyGraph with 14 nodes>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DependencyGraph(inp,cell_separator=\"\\t\", top_relation_label=\"root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear what's messing up the script! The parser has trouble with the cell separator in cases like that:\n",
    "* ' in word's final position (as in \"c'\" of wrong_sents[0], word 17)\n",
    "* space in the word (as in \"25 785\" of wrong_sents[1])\n",
    "\n",
    "That's easily fixed. It suffices to esplicitely set `cell_separator=\"\\t\"` for the DependencyGraph constructor in our new verions of `fixed_parsed_sents`. As tab is the official separator of CoNLL-U, this should give no problem at all to the other treebanks: I tested it with a couple of them and all went smoothly..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapbook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test if it is true that the sentences included in the study is = nr. of sents reported in the log - nr. of sentences with punct as head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from syntacticNetwork import getCoocInSent, hasPunctHead\n",
    "def TEST_NetworkDataFrames(parsed_sents, threshold=200000):\n",
    "    \"\"\"Process the parsed DependencyGraphs and return the DFs with \n",
    "    :param: parsed_sents: list of parsed Dependency Graphs\n",
    "    :param: threshold: the iteration over sentences will stop after the sentence that \n",
    "    exceeds the give threshold\n",
    "    :return: tuple of DataFrames (head-dep values, cooccurence values)\n",
    "    \"\"\"\n",
    "    head, dep, rel = [], [], []\n",
    "    w1, w2 = [], []\n",
    "    token_count = 0\n",
    "    puncthead = 0\n",
    "    included_sents = []\n",
    "    for i,s in enumerate(parsed_sents, start=1):\n",
    "        if hasPunctHead(s) == False:\n",
    "            included_sents.append((i,s))\n",
    "            #co-occurence data\n",
    "            sent = getCoocInSent(s)\n",
    "            for line in sent:\n",
    "                w1.append(line[0])\n",
    "                w2.append(line[1])\n",
    "            #syntax-based\n",
    "            for n in s.triples(word_label=\"lemma\"):\n",
    "                if n[0][1] == 'PUNCT':\n",
    "                    print(\"{}: Punctuation as head!\".format(i-1))\n",
    "                    break\n",
    "                if n[2][1] == \"PUNCT\":\n",
    "                    continue\n",
    "                head.append(n[0][0])\n",
    "                #htag.append(n[0][1])\n",
    "                #clean relation feature:\n",
    "                rel.append(n[1].split(\":\")[0])\n",
    "                dep.append(n[2][0])\n",
    "                #dtag.append(n[2][1])\n",
    "            token_count = token_count + countNodes(s)\n",
    "        else:\n",
    "            puncthead += 1\n",
    "        if token_count > threshold:\n",
    "            print(\"Sentences with punctuation as head: {}\".format(puncthead))\n",
    "            #logging.info(\"Nr. of Sentences included: {}\".format(i))\n",
    "            #logging.info(\"Nr. of Tokens included: {}\".format(token_count))\n",
    "            print(\"Finalizing the Dataframe at {} tokens after {} sentences\".format(token_count, i))\n",
    "            break\n",
    "    #df_dep = pd.DataFrame({\"Head_Lemma\" : head, \"Dep_Lemma\" : dep, \"Relation\" : rel })\n",
    "    #df_dep = df_dep[[\"Head_Lemma\", \"Dep_Lemma\", \"Relation\"]]\n",
    "    #df_co = pd.DataFrame({\"Prec\": w1, \"Seq\" : w2})\n",
    "    return (included_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de-ud-dev.conllx', 'de-ud-train.conllx']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidep.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with punctuation as head: 11\n",
      "Finalizing the Dataframe at 200010 tokens after 12396 sentences\n"
     ]
    }
   ],
   "source": [
    "inc = TEST_NetworkDataFrames(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12385"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is indeed 12396 - 11!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
